{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework for MRI reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, os\n",
    "from functions import transforms as T\n",
    "from functions.subsample import MaskFunc\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.measure import compare_ssim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slices(data, slice_nums, cmap=None): # visualisation\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(DataLoader):\n",
    "    def __init__(self, data_list, acceleration, center_fraction, use_seed):\n",
    "        self.data_list = data_list\n",
    "        self.acceleration = acceleration\n",
    "        self.center_fraction = center_fraction\n",
    "        self.use_seed = use_seed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_id = self.data_list[idx]\n",
    "        return get_epoch_batch(subject_id, self.acceleration, self.center_fraction, self.use_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_batch(subject_id, acc, center_fract, use_seed=True):\n",
    "    ''' random select a few slices (batch_size) from each volume'''\n",
    "\n",
    "    fname, rawdata_name, slice = subject_id  \n",
    "    \n",
    "    with h5py.File(rawdata_name, 'r') as data:\n",
    "        rawdata = data['kspace'][slice]\n",
    "    print(rawdata.shape)\n",
    "                      \n",
    "    slice_kspace = T.to_tensor(rawdata).unsqueeze(0)\n",
    "    S, Ny, Nx, ps = slice_kspace.shape\n",
    "\n",
    "    # apply random mask\n",
    "    shape = np.array(slice_kspace.shape)\n",
    "    mask_func = MaskFunc(center_fractions=[center_fract], accelerations=[acc])\n",
    "    seed = None if not use_seed else tuple(map(ord, fname))\n",
    "    mask = mask_func(shape, seed)\n",
    "      \n",
    "    # undersample\n",
    "    masked_kspace = torch.where(mask == 0, torch.Tensor([0]), slice_kspace)\n",
    "    masks = mask.repeat(S, Ny, 1, ps)\n",
    "\n",
    "    img_gt, img_und = T.ifft2(slice_kspace), T.ifft2(masked_kspace)\n",
    "    #print(img_gt.shape)\n",
    "    # perform data normalization which is important for network to learn useful features\n",
    "    # during inference there is no ground truth image so use the zero-filled recon to normalize\n",
    "    norm = T.complex_abs(img_und).max()\n",
    "    if norm < 1e-6: norm = 1e-6\n",
    "    \n",
    "    # normalized data\n",
    "    img_gt, img_und, rawdata_und = img_gt/norm, img_und/norm, masked_kspace/norm\n",
    "    #print((img_gt.squeeze(0)).shape)\n",
    "    return img_gt.squeeze(0), img_und.squeeze(0), rawdata_und.squeeze(0), masks.squeeze(0), norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_path(train_data_path, val_data_path):\n",
    "    \"\"\" Go through each subset (training, validation) and list all \n",
    "    the file names, the file paths and the slices of subjects in the training and validation sets \n",
    "    \"\"\"\n",
    "\n",
    "    data_list = {}\n",
    "    train_and_val = ['train', 'val']\n",
    "    data_path = [train_data_path, val_data_path]\n",
    "      \n",
    "    for i in range(len(data_path)):\n",
    "\n",
    "        data_list[train_and_val[i]] = []\n",
    "        \n",
    "        which_data_path = data_path[i]\n",
    "    \n",
    "        for fname in sorted(os.listdir(which_data_path)):\n",
    "            \n",
    "            subject_data_path = os.path.join(which_data_path, fname)\n",
    "                     \n",
    "            if not os.path.isfile(subject_data_path): continue \n",
    "            \n",
    "            with h5py.File(subject_data_path, 'r') as data:\n",
    "                num_slice = data['kspace'].shape[0]\n",
    "                \n",
    "            # the first 5 slices are mostly noise so it is better to exlude them\n",
    "            data_list[train_and_val[i]] += [(fname, subject_data_path, slice) for slice in range(5, num_slice)]\n",
    "    \n",
    "    return data_list    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Block that consists of two convolution layers each followed by\n",
    "    instance normalization, relu activation and dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, drop_prob):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input.\n",
    "            out_chans (int): Number of channels in the output.\n",
    "            drop_prob (float): Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(drop_prob),\n",
    "            nn.Conv2d(out_chans, out_chans, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(drop_prob)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]\n",
    "        Returns:\n",
    "            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]\n",
    "        \"\"\"\n",
    "        return self.layers(input)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'ConvBlock(in_chans={self.in_chans}, out_chans={self.out_chans}, ' \\\n",
    "            f'drop_prob={self.drop_prob})'\n",
    "\n",
    "\n",
    "class UnetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of a U-Net model.\n",
    "    This is based on:\n",
    "        Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks\n",
    "        for biomedical image segmentation. In International Conference on Medical image\n",
    "        computing and computer-assisted intervention, pages 234â€“241. Springer, 2015.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, chans, num_pool_layers, drop_prob):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input to the U-Net model.\n",
    "            out_chans (int): Number of channels in the output to the U-Net model.\n",
    "            chans (int): Number of output channels of the first convolution layer.\n",
    "            num_pool_layers (int): Number of down-sampling and up-sampling layers.\n",
    "            drop_prob (float): Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.chans = chans\n",
    "        self.num_pool_layers = num_pool_layers\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.down_sample_layers = nn.ModuleList([ConvBlock(in_chans, chans, drop_prob)])\n",
    "        ch = chans\n",
    "        for i in range(num_pool_layers - 1):\n",
    "            self.down_sample_layers += [ConvBlock(ch, ch * 2, drop_prob)]\n",
    "            ch *= 2\n",
    "        self.conv = ConvBlock(ch, ch, drop_prob)\n",
    "\n",
    "        self.up_sample_layers = nn.ModuleList()\n",
    "        for i in range(num_pool_layers - 1):\n",
    "            self.up_sample_layers += [ConvBlock(ch * 2, ch // 2, drop_prob)]\n",
    "            ch //= 2\n",
    "        self.up_sample_layers += [ConvBlock(ch * 2, ch, drop_prob)]\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch // 2, kernel_size=1),\n",
    "            nn.Conv2d(ch // 2, out_chans, kernel_size=1),\n",
    "            nn.Conv2d(out_chans, out_chans, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]\n",
    "        Returns:\n",
    "            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]\n",
    "        \"\"\"\n",
    "        stack = []\n",
    "        output = input\n",
    "        # Apply down-sampling layers\n",
    "        for layer in self.down_sample_layers:\n",
    "            output = layer(output)\n",
    "            stack.append(output)\n",
    "            output = F.max_pool2d(output, kernel_size=2)\n",
    "\n",
    "        output = self.conv(output)\n",
    "\n",
    "        # Apply up-sampling layers\n",
    "        for layer in self.up_sample_layers:\n",
    "            output = F.interpolate(output, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "            output = torch.cat([output, stack.pop()], dim=1)\n",
    "            output = layer(output)\n",
    "        return self.conv2(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim(gt, pred):\n",
    "    \"\"\" Compute Structural Similarity Index Metric (SSIM). \"\"\"\n",
    "    return compare_ssim(\n",
    "        gt.transpose(1, 2, 0), pred.transpose(1, 2, 0), multichannel=True, data_range=gt.max()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    data_path_train = '../train'\n",
    "    data_path_val = '../train'\n",
    "    data_list = load_data_path(data_path_train, data_path_val) # first load all file names, paths and slices.\n",
    "\n",
    "    # set mask\n",
    "    acc = 8\n",
    "    cen_fract = 0.04 \n",
    "    seed = False # random masks for each slice \n",
    "    num_workers = 0 # data loading is faster using a bigger number for num_workers. 0 means using one cpu to load data\n",
    "    \n",
    "    # create data loader for training set. It applies same to validation set as well\n",
    "    train_dataset = MRIDataset(data_list['train'], acceleration=acc, center_fraction=cen_fract, use_seed=seed)\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=1, num_workers=num_workers)\n",
    "    \n",
    "    # set device\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    # set model\n",
    "    net = UnetModel(1,1,32,4,0.0).to(device)\n",
    "\n",
    "    # set optimizer\n",
    "    optimizer = torch.optim.RMSprop(net.parameters(), lr=1e-3)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 40, 0.1)\n",
    "    \n",
    "    # run model\n",
    "    crop_size = [320,320]\n",
    "    EPOCHS = 50\n",
    "    for epoch in range(EPOCHS):\n",
    "        scheduler.step(epoch)\n",
    "        net.train()\n",
    "        avg_loss = 0.\n",
    "        global_step = epoch * len(train_loader)\n",
    "        for iter, data in enumerate(train_loader):\n",
    "            input, target, mean, std, norm = data\n",
    "            input = T.center_crop(T.complex_abs(input.unsqueeze(1)),crop_size).to(device)\n",
    "            target = T.center_crop(T.complex_abs(target),crop_size).to(device)\n",
    "            output = net(input).squeeze(1)\n",
    "            loss = F.l1_loss(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss = 0.99 * avg_loss + 0.01 * loss.item() if iter > 0 else loss.item()\n",
    "        print(avg_loss)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_ssim = 0\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        input, target, mean, std, norm = data\n",
    "        input = T.center_crop(T.complex_abs(input.unsqueeze(1)),crop_size).to(device)\n",
    "        target = T.center_crop(T.complex_abs(target),crop_size).to(device)\n",
    "        output = net(input).squeeze(1)\n",
    "        temp = ssim(target.cpu().detach().numpy(), output.cpu().detach().numpy())\n",
    "        print(temp)\n",
    "        ave_ssim+=temp\n",
    "        cnt+=1\n",
    "print(\"ave: \",ave_ssim/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict,'../trainedmodel/L1loss8af.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
